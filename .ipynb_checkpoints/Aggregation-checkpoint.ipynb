{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 组合模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 动机\n",
    "\n",
    "组合模型可以实现提高模型能力（踩油门），又可以实现正则化（踩刹车），好像把两个矛盾的东西结合在了一起。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在$g_t$已知的情况下，有三种组合方法：\n",
    "\n",
    "+ Uniform Blending\n",
    " + 二元分类\n",
    " \n",
    "  $$G(x) = sign(\\sum_T g_t(x))$$\n",
    "  \n",
    " + 多元分类\n",
    " \n",
    "  $$G(x) = arg\\max_K \\sum_T 1(g_t(x) = k)$$\n",
    " \n",
    " + 回归\n",
    " \n",
    "  $$G(x) = \\frac{1}{T} \\sum_T g_t(x)$$\n",
    " \n",
    " 可以证明，单个g的$E_{out}$的期望值比G的$E_{out}$大。\n",
    " \n",
    " \n",
    "+ Linear Blending\n",
    " + 二元分类\n",
    " \n",
    "  $$G(x) = \\hat{g}(\\Phi(x))$$\n",
    "  \n",
    " + 多元分类\n",
    " \n",
    "  $$G(x) = \\hat{g}(\\Phi(x))$$\n",
    "  \n",
    " + 回归\n",
    " \n",
    "  $$G(x) = \\hat{g}(\\Phi(x))$$\n",
    "   \n",
    " 算法：把D分为$D_{train}$和$D_{val}$，在前者上训练得到各个$g_t^{-}$，另$\\Phi^{-}(x) = (g_1^{-}(x),...,g_t^{-}(x))$，然后把$D_{val}$中的数据$(x_n, y_n)$变换为$(z_n = \\Phi^{-}(x_n), y_n)$。用变换后新数据在$D_{val}$上训练一个线性模型（超参数），得到$\\hat{g}$，其参数是$\\alpha$。\n",
    " \n",
    " 注意我们在G中采用的是$\\Phi(x) = (g_1(x),...,g_t(x))$，而不是$\\Phi^{-}$。g是在D上训练得到，而$g_{-}$只在$D_{train}$上训练得到。另外，从上面$\\alpha$的G的求解可以看出，各个$g_t$相当于对原数据做了一个特征变换：$x -> (g_1(x),...,g_t(x))$\n",
    " \n",
    " \n",
    "+ Conditional Blending (Stacking，又叫Any Blending)\n",
    "\n",
    " 在经过和Linear Blending一样的特征变换后，利用这些新的数据在$D_{val}$上训练一个非线性模型（超参数），得到$\\hat{g}$，然后G就变为：\n",
    " \n",
    " + 二元分类\n",
    " \n",
    "  $$G(x) = \\hat{g}(\\Phi(x))$$\n",
    "  \n",
    " + 多元分类\n",
    " \n",
    "  $$G(x) = \\hat{g}(\\Phi(x))$$\n",
    "  \n",
    " + 回归\n",
    " \n",
    "  $$G(x) = \\hat{g}(\\Phi(x))$$\n",
    " \n",
    " 之所以Linear Blending和Stacking都是在$D_{val}$进行组合模型的选择，原因和Validation的必要性是一个道理。其实Validation可以看做上述三种方法以外的另一种组合模型，那便是$G(x) = (arg\\min_{T} E_{val}(g_t)) (x)$。即最后的组合模型中只保留$E_{val}$最小的g。相应的，前三种方法也可以进行Cross Validation，以便最后得到的G的$E_{val}$更接近$E_{out}$。那么就可以在多个G之间做选择。（有没有必要？因为组合的时候可以通过权重控制各个g的作用程度）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在$g_t$未知的情况下，我们必须先求出$g_t$，然后组合。也有三种方法：\n",
    "\n",
    "+ Bagging\n",
    "\n",
    "+ Adaptive Boosting (AdaBoost)\n",
    "\n",
    "+ Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
