{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一. Original Hard-marginal SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 动机：找一条胖胖的分割线，使得算法的VC维低，即所得模型的通用性高，不容易过拟合（相对于PLA）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 抽象为最优化问题，并将公式一步步转化为容易解决的二次规划问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\max\\limits_{w,b} fatness(w, b)$$\n",
    "$$s.t.$$\n",
    "$$y_n (w^T x_n + b) \\geq 0$$\n",
    "$$fatness(w, b) = \\min\\limits_{0 \\leq n < N} distance(x_n, w, b) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Downarrow margin \\leftarrow fatness, 展开distance, 且意识到y_n (w^T x_n + b) =|w^T x_n + b|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\max \\limits_{w,b} margin(w, b)$$\n",
    "$$s.t.$$\n",
    "$$margin(w, b) = \\min\\limits_{0 \\leq n < N} \\frac{1}{||w||} y_n (w^T x_n + b) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Downarrow 利用平面的放缩不变性，使得margin(w,b) = \\frac{1}{||w||} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\max \\limits_{w,b} \\frac{1}{||w||} $$\n",
    "$$s.t.$$\n",
    "$$\\min\\limits_{0 \\leq n < N}  y_n (w^T x_n + b) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Downarrow 放松限制条件，将最大化变最小化，点积代替取模运算 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\min \\limits_{w,b} \\frac{1}{2} w^T w $$\n",
    "$$s.t.$$\n",
    "$$y_n (w^T x_n + b) \\geq 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    上述放松限制条件的操作之所以有效，可以用反证法证明在放松的限制条件下得到的w和b和原问题一致．上述问题可以直接丢到现成的二次规划算法里面求解．上述分类平面是线性的，若要实现非线性的效果，可以对原始特征进行转化（到高维空间）．下面就用解二次规划的方法来实现SVM，其中所用Solver来自CVXOPT包："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\min \\frac{1}{2}u^T Q u + p^T u $$\n",
    "$$ s.t. $$\n",
    "$$ G u \\leq h $$\n",
    "$$ A u = b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ u = \\left[ \\begin{array}{c} b \\\\ w \\\\ \\end{array} \\right], Q = \\left[ \\begin{array}{cc} 0 & 0_{1*d} \\\\ 0_{d*1} & I_{d*d} \\end{array} \\right], p = 0_{(d+1)*1}, G_{n*(d+1)} = \\left[ \\begin{array}{c} . \\\\ . \\\\ -y_n [1, x_n^T] \\\\ \\end{array} \\right], h = -1_{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ cvxopt.solvers.qp(Q, p, [, G, h [, A, b]]) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris = zip(iris.data, iris.target)\n",
    "iris_01 = filter(lambda (X, y): y == 0 or y == 1, iris)\n",
    "X = np.array(map(lambda (X, y): X, iris_01))\n",
    "Y = np.array(map(lambda (X, y): 1 if y == 0 else -1, iris_01))\n",
    "Y.shape = (len(X), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  2.4812e-01  1.0145e+01  2e+02  2e+00  2e+02\n",
      " 1:  1.7120e+00 -1.5715e+01  2e+01  1e-01  2e+01\n",
      " 2:  1.3950e+00 -3.9311e-01  2e+00  5e-03  8e-01\n",
      " 3:  7.6712e-01  4.7966e-01  3e-01  5e-04  7e-02\n",
      " 4:  8.1919e-01  5.6098e-01  3e-01  3e-04  5e-02\n",
      " 5:  7.5770e-01  7.0585e-01  5e-02  3e-05  5e-03\n",
      " 6:  7.4821e-01  7.4619e-01  2e-03  2e-07  2e-05\n",
      " 7:  7.4806e-01  7.4804e-01  2e-05  2e-09  2e-07\n",
      " 8:  7.4806e-01  7.4806e-01  2e-07  2e-11  2e-09\n",
      "Optimal solution found.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "b:\n",
      "1.45056228325\n",
      "w:\n",
      "[-4.60e-02]\n",
      "[ 5.22e-01]\n",
      "[-1.00e+00]\n",
      "[-4.64e-01]\n",
      "\n",
      "CPU times: user 3.54 ms, sys: 1.5 ms, total: 5.05 ms\n",
      "Wall time: 3.89 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = X.shape[1]\n",
    "n = X.shape[0]\n",
    "Q = np.eye(d + 1)\n",
    "Q[0][0] = 0\n",
    "p = np.zeros((d + 1, 1))\n",
    "G = np.hstack((np.ones((n, 1)), X)) * -Y\n",
    "h = - np.ones((n, 1))\n",
    "\n",
    "Q = matrix(Q)\n",
    "p = matrix(p)\n",
    "G = matrix(G)\n",
    "h = matrix(h)\n",
    "\n",
    "sol = solvers.qp(Q, p, G, h)\n",
    "\n",
    "b = sol['x'][0]\n",
    "w = sol['x'][1:]\n",
    "print '-' * 100\n",
    "print 'b:'\n",
    "print b\n",
    "print 'w:'\n",
    "print w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二. Dual Hard-marginal SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 动机：原始二次规划问题的复杂度跟特征的维度有关系，即效率受限于特征的维度．想办法去除这一限制，以便可以对特征进行任意扩充，甚至可以扩充到无限维．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
